{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cours 6 : Un réseau de neurones (TP 10-11)<span class=\"tocSkip\"></span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce chapitre, nous allons explorer l'algorithme \"vanilla\" du réseau de neurones dans un objectif de classification pas à pas. # Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Charger les données de la base des femmes ayant un cancer du sein. Stocker dans X les informations sur la femme, et Y la variable cible (cancer/pas cancer). Trouver aussi le nom de toutes les variables et stocker les dans features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=load_breast_cancer()[\"data\"]\n",
    "y=load_breast_cancer()[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=load_breast_cancer()[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Séparer en 80% - 20% X et y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Normaliser les données du train et du test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "X_train_stand=ss.fit_transform(X_train)\n",
    "X_test_stand=ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Transposer les données pour qu'il soit de la forme (m,n), m : nombre de variables, n : nombre d'observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_fin=X_train_stand.T\n",
    "X_test_fin=X_test_stand.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 455)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Créer la fonction d'initialisation des paramètres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layers,seed):\n",
    "    '''\n",
    "    layers: une liste qui contient le nombre de neurones par couche\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    params = {}  \n",
    "    print(\"{} Layers parameters init\".format(len(layers)))\n",
    "\n",
    "    for l in range(1, len(layers)):\n",
    "        params[\"W\" + str(l)] = np.random.randn(layers[l],layers[l-1])\n",
    "        params[\"b\" + str(l)] = np.zeros((layers[l],1))\n",
    "    return params  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Créer les fonctions sigmoid et relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    element-wise sigmoid \n",
    "    '''\n",
    "    sig = 1/(1+np.exp(-z))\n",
    "    return sig\n",
    "def relu(z):\n",
    "    '''\n",
    "    element-wise relu\n",
    "    '''\n",
    "    rel = max(0,z)\n",
    "    return rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Créer les fonctions dérivées de sigmoid et relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_deriv(z):\n",
    "    if z<=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def sigmoid_deriv(z):\n",
    "    x=sigmoid(z)*(1-sigmoid(z))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Créer une fonction qui retourne la nouvelle matrice A à partir de l'ancienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward step\n",
    "def forward(A, W, b, activation=\"relu\"):\n",
    "    '''\n",
    "    Implement one step of forward\n",
    "    cache: contains A,W,b,Z; stored for computing the backward pass efficiently\n",
    "    '''\n",
    "    Z_new = np.dot(W,A)+b\n",
    "    if activation==\"relu\":\n",
    "        A_new = relu(Z_new)\n",
    "    if activation==\"sigmoid\":\n",
    "        A_new = sigmoid(Z_new)\n",
    "        \n",
    "    cache = ((A,W,b),Z_new)\n",
    "    \n",
    "    return A_new, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Créer la fonction qui le fait pour toutes les couches jusqu'à l'output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prop_forward(X, params, activation=\"relu\"):\n",
    "    '''\n",
    "    Implement forward propagation for the same activation for all layers, and finalizing with sigmoid\n",
    "    '''\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(params)//2 \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_old = A\n",
    "        A, cache = forward(A_old,params[\"W\"+str(l)],params[\"b\"+str(l)],activation=activation)\n",
    "        caches.append(cache)\n",
    "        \n",
    "    A_pred, cache = forward(A,params[\"W\"+str(L)],params[\"b\"+str(L)],activation=\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return A_pred, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Créer la fonction de coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cost step\n",
    "def compute_cost(A_pred,y,params,lambd=0):\n",
    "    '''\n",
    "    cross-entropy cost\n",
    "    '''\n",
    "    m = y.shape[1]\n",
    "    cost = -(1/m)*(np.dot(np.log(A_pred),y.T)+np.dot(np.log(1-A_pred),(1-y).T))\n",
    "    cost=np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Maintenant dans le sens inverse, à partir de l'output AL, créer une fonction pour déterminer les gradients de W et b pour chaque layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Backward Step\n",
    "def relu_dZ(dA,z_cache):\n",
    "    dZ=dA*relu_deriv(z_cache)\n",
    "    return dZ\n",
    "def sigmoid_dZ(dA,z_cache):\n",
    "    dZ=dA*sigmoid_deriv(z_cache)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sub_back(dZ, cache,d_cache,lambd=0,keep_prob=1):\n",
    "    \"\"\"\n",
    "    Compute DWl,dbl,DA_old based on dZl\n",
    "    \"\"\"\n",
    "    A_old, W, b = cache\n",
    "    m = A_old.shape[0]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_old.T)+(lambd/m)*W\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_old = (np.dot(W.T,dZ)*d_cache)/keep_prob\n",
    "    \n",
    "    return dA_old, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(dA, cache, activation,lambd=0,keep_prob=1):\n",
    "    \"\"\"\n",
    "    compute one-step of backward prop\n",
    "    \"\"\"\n",
    "    awb_cache, z_cache,d_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_dZ(dA,z_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_dZ(dA,z_cache)\n",
    "        \n",
    "    dA_prev, dW, db = sub_back(dZ,awb_cache,d_cache,lambd,keep_prob)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prop_backward(AL, Y, caches,activation,lambd=0, keep_prob=1):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\"+str(L)], grads[\"dW\"+str(L)], grads[\"db\"+str(L)] = backward(dAL,current_cache,\"sigmoid\",lambd,keep_prob)\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = backward(grads[\"dA\"+str(l+2)],current_cache,activation,lambd,keep_prob)\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Créer une fonction pour rafraichir les paramètres W et b par Gradient descendant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):  \n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(1,L+1):\n",
    "        parameters[\"W\"+str(l)]=parameters[\"W\"+str(l)]-learning_rate*grads[\"dW\"+str(l)]\n",
    "        parameters[\"b\"+str(l)]=parameters[\"b\"+str(l)]-learning_rate*grads[\"db\"+str(l)]        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Fitter un réseau de neurones à 3 couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Fitting(X,Y,layers,activation,learning_rate = 0.00175, num_iterations = 3000, print_cost=True,seed=10):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network\n",
    "    \"\"\"\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    params = initialize_parameters_deep(layers,seed)\n",
    "    for i in range(0, num_iterations):\n",
    "        #forward prop\n",
    "        AL, caches = prop_forward(X,params,activation)\n",
    "        cost = compute_cost(AL,Y,params)\n",
    "\n",
    "        #backward prop\n",
    "        grads = prop_backward(AL,Y,caches,activation)\n",
    " \n",
    "        # Updating parameters\n",
    "        params = update_parameters(params,grads,learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 500 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        costs.append(cost)\n",
    "    \n",
    "    return params,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Layers parameters init\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-2c362d2ddb52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-7b275ea43d9a>\u001b[0m in \u001b[0;36mFitting\u001b[0;34m(X, Y, layers, activation, learning_rate, num_iterations, print_cost, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#forward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-f055d7332318>\u001b[0m in \u001b[0;36mprop_forward\u001b[0;34m(X, params, activation)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mA_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_old\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcaches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-703dd2541eb3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(A, W, b, activation)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mZ_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mA_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-09e1a763b51d>\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0melement\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwise\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     '''\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "lr=0.001\n",
    "activation=\"relu\"\n",
    "final_params,cost=Fitting(X_train,y_train,[X_train.shape[0],15,4,1],activation,learning_rate=lr,num_iterations=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Créer la fonction Predict, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Predict(X_test,params):\n",
    "    return(y_pred_prob,y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob,y_pred_classes=Predict(X_dev,final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_dev=NN.compute_cost(y_pred_prob,y_dev,final_params)\n",
    "print(\"MSE on the dev set {}\".format(mse_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_dev=ST.accuracy(y_pred_classes,y_dev)\n",
    "print(\"ACCURACY on the dev set {}\".format(acc_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(cost))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(lr))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
